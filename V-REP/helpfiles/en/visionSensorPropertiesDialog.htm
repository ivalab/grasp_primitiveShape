<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Strict//EN">
<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<title>Vision sensor properties</title>
<link rel="stylesheet" type="text/css" href="../style.css">
</head>

<body>

<div align="center">
<table class=allEncompassingTable >
 <tr>
  <td >
<p><a href="../index.html" TARGET="_top"><img src="images/homeImg.png"></a></p>



<h1>Vision sensor properties</h1>

<p>The vision sensor properties are part of the <a href="sceneObjectPropertiesDialog.htm">scene object properties </a>dialog, which is located at [Menu bar --&gt; Tools --&gt; Scene object properties]. You can also open the dialog with a double-click on an object icon in the <a href="userInterface.htm#SceneHierarchy">scene hierarchy</a>, or with a click on its <a href="userInterface.htm#toolbars">toolbar</a> button:<br>
</p>

<p align=center><img src="images/objectPropertyToolbarButton.jpg"></p>
<p class=imageLabel>[Scene object properties toolbar button]</p>
<br>

<p>In the scene object properties dialog, click  the <strong>Vision sensor</strong> button to display the vision sensor dialog (the <strong>Vision sensor</strong> button only appears if the last selection is a <a href="visionSensors.htm">vision sensor</a><a href="proximitySensors.htm"></a><a href="graphs.htm"></a><a href="dummies.htm"></a><a href="joints.htm"></a><a href="shapes.htm"></a><a href="lights.htm"></a><a href="cameras.htm"></a><a href="paths.htm"></a>). The dialog displays the settings and parameters of the last selected vision sensor. If more than one vision sensor is selected, then some parameters can be copied from the last selected vision sensor to the other selected vision sensors (<strong>Apply to selection</strong>-buttons):<br>
</p>



<p align=center><img src="images/visionSensorDialog1.jpg"></p>
<p class=imageLabel>[Vision sensor dialog]</p>
<br>


<li><strong>Enable all vision sensors</strong>: turns the vision sensor functionality on and off for all vision sensors.<br>
</li>

<li><strong>Explicit handling</strong>: indicates whether the sensor should be explicitely handled. If checked, the sensor will not be handled when sim.handleVisionSensor(sim.handle_all_except_explicit) is called, but only if sim.handleVisionSensor(sim.handle_all) or sim.handleVisionSensor(visionSensorHandle) is called. This is useful if the user wishes to handle the sensor in a <a href="childScripts.htm">child script</a> rather than in the <a href="mainScript.htm">main script</a> (if not checked the sensor will be handled twice, once when sim.handleVisionSensor(sim.handle_all_except_explicit) is called in the main script, and once when sim.handleVisionSensor(visionSensorHandle) is called in the child script). Refer also to the section on <a href="explicitHandling.htm">explicit and non-explicit calls</a>.<br>
</li>

<li><strong>External input</strong>: when selected, then the vision sensor's normal operation will be altered so as to be able to treat and filter external images instead (e.g. video images).<br>
</li>

<li><strong>Perspective mode</strong>: allows selecting between the perspective projection type and the orthogonal projection type vision sensor.<br>
</li>

<li><strong>Ignore RGB info (faster)</strong>: if selected, the RGB information of the sensor (i.e. the color) will be ignored so that it can operate faster. Use this option if you only rely on the depth information of the sensor.</li>

<li><strong>Ignore depth info (faster)</strong>: if selected, the depth information of the sensor will be ignored so that it can operate faster. Use this option if you do not intend to use the depth information of the sensor.</li>

<li><strong>Packet1 is blank (faster)</strong>: if selected, then V-REP won't automatically extract specific information from acquired images, so that it can operate faster. Use this option if you do not intend to use the first packet of auxiliary values returned by API functions <a href="regularApi/simReadVisionSensor.htm">sim.readVisionSensor</a> or <a href="regularApi/simHandleVisionSensor.htm">sim.handleVisionSensor</a>.</li>

<li> <strong>Use local lights</strong>: if enabled, then only local lights parented with this vision sensor (i.e. built on top of this vision sensor) will be activated when displaying this vision sensor's image content. <a href="lights.htm">Lights</a> can be made local in the <a href="lightPropertiesDialog.htm">light properties</a>. </li>

<li> <strong>Show fog if enabled</strong>: if disabled, then this vision sensor won't see any fog if fog is enabled. Also refer to the <a href="environmentPropertiesDialog.htm">environment dialog</a>.<br>
</li>


<li><strong>Render mode</strong>: three modes are currently available:</li>
<li class=tabTab><strong>OpenGL</strong> (default): renders the visible color channels of objects.</li>
<li class=tabTab><strong>OpenGL, auxiliary channels</strong>: renders the auxiliary color channels of objects. The auxiliary channels red, green and blue colors are meant to be used in following way: red is the temperature channel (0.5 is the ambient temperature), green is the user defined channel, and blue is the active light emitter channel.</li>
<li class=tabTab><strong>OpenGL, color coded handles</strong>: renders the objects by coding their handles into the colors. The first data packet returned by the <a href="regularApi/simReadVisionSensor.htm">sim.readVisionSensor</a> or <a href="regularApi/simHandleVisionSensor.htm">sim.handleVisionSensor</a> API functions represent the detected object handles (round the values down).</li>
<li class=tabTab><strong>POV-Ray</strong>: uses the POV-Ray plugin to render images, allowing for shadows (also soft shadows) and material effects (much slower). The plugin source code is located <a href="https://github.com/CoppeliaRobotics/v_repExtPovRay" target="_blank">here</a>.</li>
<li class=tabTab><strong>External renderer</strong>: uses an external renderer implemented via a plugin. The current external renderer source code is located <a href="https://github.com/CoppeliaRobotics/v_repExtExternalRenderer" target="_blank">here</a>.</li>
<li class=tabTab><strong>External renderer, windowed</strong>: uses an external renderer implemented via a plugin, and displays the image in an external window (during simulation only). The current external renderer source code is located <a href="https://github.com/CoppeliaRobotics/v_repExtExternalRenderer" target="_blank">here</a>.</li>
<li class=tabTab><strong>OpenGL3</strong>: uses the <a href="https://github.com/stepjam/v_repExtOpenGL3Renderer">OpenGL3 renderer plugin</a>, courtesy of Stephen James. The plugin offers shadow casting, which is currently not possible natively, in V-REP. Light projection and shadows can be adjusted for each light, via the object's <a href="commonPropertiesDialog.htm#extensionString">extension string</a>, e.g. <em>openGL3 {lightProjection {nearPlane {0.1} farPlane {10} orthoSize {8} bias {0.001} normalBias {0.005} shadowTextureSize {2048}}}</em></li>
<li class=tabTab><strong>OpenGL3, windowed</strong>: same as above, but windowed.</li>


<li><strong>Near / far clipping plane</strong>: the minimum / maximum distance from which the sensor will be able to detect.<br>
</li>

<li><strong>Perspective angle</strong>: the maximum opening angle of the detection volume when the sensor is in perspective mode.<br>
</li>

<li><strong>Orthographic size</strong>: the maximum size (along x or y) of the detection volume when the sensor is not in perspective mode.<br>
</li>

<p align=center><img src="images/visionSensorDialog2.jpg"></p>
<p class=imageLabel>[Detection value parameters of the orthographic-type vision sensor]</p>
<br>

<p align=center><img src="images/visionSensorDialog3.jpg"></p>
<p class=imageLabel>[Detection value parameters of the perspective-type vision sensor]</p>
<br>

<li><strong>Resolution X / Y</strong>: desired x- / y-resolution of the image captured by the vision sensor. Carefully chose the resolution depending on your application (high resolution will result in slower operation). With older graphic card models, the actual resolution might be different from what is indicated here (old graphic card models only support resolutions at 2^n, where n is 0, 1, 2, etc.).<br>
</li>

<li><strong>Entity to detect</strong>: allows specifying what <a href="entities.htm">entity</a> should be rendered.</li>


<li><strong>Adjust default image color</strong>: allows specifying the color that should be used in areas where nothing was rendered. By default, the <a href="environment.htm">environment</a> fog color is used.<br>
</li>

<li><strong>Object size X / Y / Z</strong>: size of the body-part of the vision sensor. This has no functional effect.</li>

<li><strong>Show volume when not detecting</strong>: if selected, the detection volume is shown when the sensor didn't trigger.</li>

<li><strong>Show volume when detecting</strong>: if selected, the detection volume is shown when the sensor triggered.</li>

<li><strong>Object colors</strong>: allows adjusting the various colors of a vision sensor.</li>

<li><strong>Show filter dialog</strong>: toggles the <a href="visionSensorFilterDialog.htm">vision sensor filter dialog</a>. That dialog allows specifying filters to apply to captured images. </li>

<br>
<h3 class=recommendedTopics>Recommended topics</h3>
<li><a href="visionSensors.htm">Vision sensors</a></li>
<li><a href="visionSensorDescription.htm">Vision sensor types and mode of operation</a></li>
<li><a href="visionSensorFilterDialog.htm">Vision sensor filter dialog</a></li>
<li><a href="visionSensorFilterComposition.htm">Vision sensor filter composition</a></li>
<li><a href="renderableObjects.htm">Renderable objects</a></li>
<li><a href="commonPropertiesDialog.htm">Object common properties</a></li>

<br>
<br>

 </tr>
</table> 
</div>  
  
  
</body>

</html>
